# Chatbot-For-Analyzing-PDF
It analyzes the pdf and gives the responses
ğŸ“Œ Project: Flask-based AI Chatbot Backend

This project is a Flask-powered backend API designed to support an AI chatbot with two core capabilities:

Interactive Chat Handling â€“ Processes user queries and generates intelligent responses.

Document Processing â€“ Accepts uploaded PDF/text documents, analyzes their content, and allows users to ask context-based questions.

âš™ï¸ Features

REST API Endpoints

/process-message â†’ Accepts a user message and returns a chatbot-generated response.

/process-document â†’ Accepts and processes an uploaded file (e.g., PDF) for knowledge extraction.

/ â†’ Serves the front-end interface (index.html).

CORS Support â†’ Ensures smooth integration with frontend applications.

Worker Integration â†’ Delegates heavy AI/NLP tasks (e.g., prompt processing, document parsing) to a separate worker.py module.

Error Handling â†’ Handles invalid file uploads gracefully.

Cross-platform Deployment â†’ Runs on 0.0.0.0:8000 for local or containerized environments.

ğŸ—ï¸ Tech Stack

Backend: Flask (Python)

CORS: Flask-CORS

Logging: Python logging

Worker Module: Custom Python module (worker.py) for AI/NLP processing

ğŸš€ API Usage
1ï¸âƒ£ Process User Message

Endpoint:

POST /process-message


Request (JSON):

{
  "userMessage": "What is AI?"
}


Response:

{
  "botResponse": "AI stands for Artificial Intelligence..."
}

2ï¸âƒ£ Process Document Upload

Endpoint:

POST /process-document


Request (Form-Data):

file: PDF/Text file

Response:

{
  "botResponse": "Thank you for providing your PDF document. I have analyzed it, so now you can ask me any questions regarding it!"
}

ğŸ“‚ Project Structure
project/
â”‚â”€â”€ app.py              # Main Flask application
â”‚â”€â”€ worker.py           # Worker module for AI/NLP logic
â”‚â”€â”€ templates/
â”‚   â””â”€â”€ index.html      # Frontend UI
â”‚â”€â”€ requirements.txt    # Python dependencies

âš¡ Run Locally
# Clone repo
git clone https://github.com/your-username/your-repo.git
cd your-repo

# Install dependencies
pip install -r requirements.txt

# Run server
python app.py


Server runs on â†’ http://localhost:8000/

ğŸ“¦ Deployment

Can be deployed on Heroku, Docker, AWS, or any cloud VM.

Exposes API on port 8000 for external access.

ğŸ”® Future Enhancements

Add authentication for secured API access

Support multiple document formats (Word, Excel, etc.)

Integration with vector databases for semantic search

Real-time streaming chatbot responses
